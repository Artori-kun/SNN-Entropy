{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373497d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from brian2 import *\n",
    "from brian2hears import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_padding(matrix, target_length=1000):\n",
    "    matrix = np.asarray(matrix)\n",
    "    \n",
    "    n_ch, T = matrix.shape\n",
    "    if T < target_length:\n",
    "        pad = np.zeros((n_ch, target_length - T), dtype=matrix.dtype)\n",
    "        return np.concatenate((matrix, pad), axis=1)\n",
    "    elif T > target_length:\n",
    "        return matrix[:, :target_length]\n",
    "    else:\n",
    "        return matrix\n",
    "\n",
    "def load_audio(file_path, sr=8000):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    return y, sr\n",
    "\n",
    "def cochleagram_from_audio(\n",
    "    y, \n",
    "    sr, \n",
    "    n_channels=8,\n",
    "    lowpass_freq=10):\n",
    "\n",
    "    sound = Sound(y * Hz, sr * Hz)\n",
    "\n",
    "    cf = erbspace(100*Hz, 8000*Hz, n_channels)\n",
    "    gammatone = Gammatone(\n",
    "        sound,\n",
    "        cf\n",
    "    )\n",
    "    envelope = FunctionFilterbank(\n",
    "        gammatone,\n",
    "        lambda x: np.maximum(x, 0)**(1.0/3.0)\n",
    "    )\n",
    "    lowpassed = LowPass(envelope, lowpass_freq)\n",
    "    \n",
    "    cochleagram = lowpassed.process()\n",
    "    cochleagram = np.array(cochleagram)\n",
    "    cochleagram = cochleagram / np.max(np.abs(cochleagram))  # Normalize the cochleagram\n",
    "    cochleagram = cochleagram.T  # Transpose to have channels as rows\n",
    "\n",
    "    return shape_padding(cochleagram)\n",
    "\n",
    "def lif_encoding(\n",
    "    cochleagram,\n",
    "    dt=1*ms,\n",
    "    duration=1000*ms,\n",
    "    tau=10*ms,\n",
    "    threshold=1.1,\n",
    "    refractory_period=5*ms,\n",
    "):\n",
    "    \n",
    "    T = int(duration / dt)\n",
    "    channels_num, _ = cochleagram.shape\n",
    "    spike_matrix = np.zeros((channels_num, T))\n",
    "    \n",
    "    decay = np.exp(-dt / tau)\n",
    "    refractory_time = refractory_period / dt\n",
    "    \n",
    "    for channel in range(channels_num):\n",
    "        v = np.zeros(T + 1)\n",
    "        refractory = False\n",
    "        refractory_counter = 0\n",
    "        \n",
    "        for t in range(T):\n",
    "            v[t + 1] = decay * v[t] + cochleagram[channel, t]\n",
    "            if v[t + 1] >= threshold:\n",
    "                v[t + 1] = 0\n",
    "                if refractory:\n",
    "                    if refractory_counter < refractory_time:\n",
    "                        refractory_counter += 1\n",
    "                    else:\n",
    "                        refractory = False\n",
    "                        refractory_counter = 0\n",
    "                else:\n",
    "                    spike_matrix[channel, t] = 1\n",
    "                    refractory = True\n",
    "\n",
    "    return spike_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "iter = 0\n",
    "\n",
    "# encode yes files\n",
    "for filepath in os.listdir(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/yes\"):\n",
    "    if filepath.endswith(\".wav\"):\n",
    "        if iter >= 100:\n",
    "            break\n",
    "        file_path = os.path.join(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/yes\", filepath)\n",
    "        y, sr = load_audio(file_path, sr=1000)\n",
    "        cochleagram = cochleagram_from_audio(y, sr)\n",
    "        spike_matrix = lif_encoding(cochleagram, refractory_period=1*ms)\n",
    "        print(f\"Processed {filepath} into spike matrix with shape {spike_matrix.shape}\")\n",
    "\n",
    "        if iter in range(0, 80):\n",
    "            # Save the spike matrix or process it further\n",
    "            np.savez_compressed(f\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/spike_data/sr1000/train/yes_{filepath[:-4]}.npz\", spike_matrix=spike_matrix, label=1)\n",
    "        elif iter in range(80, 100):\n",
    "            # Save the spike matrix or process it further\n",
    "            np.savez_compressed(f\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/spike_data/sr1000/test/yes_{filepath[:-4]}.npz\", spike_matrix=spike_matrix, label=1)\n",
    "\n",
    "        iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "\n",
    "# encode no files\n",
    "for filepath in os.listdir(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/no\"):\n",
    "    if filepath.endswith(\".wav\"):\n",
    "        if iter >= 100:\n",
    "            break\n",
    "        file_path = os.path.join(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/no\", filepath)\n",
    "        y, sr = load_audio(file_path, sr=1000)\n",
    "        cochleagram = cochleagram_from_audio(y, sr)\n",
    "        spike_matrix = lif_encoding(cochleagram, refractory_period=1*ms)\n",
    "        print(f\"Processed {filepath} into spike matrix with shape {spike_matrix.shape}\")\n",
    "        \n",
    "        if iter in range(0, 80):\n",
    "            # Save the spike matrix or process it further\n",
    "            np.savez_compressed(f\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/spike_data/sr1000/train/no_{filepath[:-4]}.npz\", spike_matrix=spike_matrix, label=0)\n",
    "        elif iter in range(80, 100):\n",
    "            # Save the spike matrix or process it further\n",
    "            np.savez_compressed(f\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/spike_data/sr1000/test/no_{filepath[:-4]}.npz\", spike_matrix=spike_matrix, label=0)\n",
    "\n",
    "        iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd58f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"sr1000/train/no_0f7205ef_nohash_0.npz\")\n",
    "spike_matrix = data['spike_matrix']\n",
    "label = data['label'].item()\n",
    "\n",
    "print(f\"Spike matrix shape: {spike_matrix.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459faee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A different approach \n",
    "# === Stable audio→cochlea→LIF spikes with dataset-wide norm + target-rate tuning ===\n",
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "# --------------------------\n",
    "# 0) Utilities\n",
    "# --------------------------\n",
    "def vad_trim(y, sr, top_db=30, pad_s=0.05):\n",
    "    \"\"\"Energy VAD (librosa) + pad both sides.\"\"\"\n",
    "    intervals = librosa.effects.split(y, top_db=top_db)\n",
    "    if len(intervals) == 0:\n",
    "        return y  # nothing detected\n",
    "    start = max(0, intervals[0,0] - int(pad_s*sr))\n",
    "    end   = min(len(y), intervals[-1,1] + int(pad_s*sr))\n",
    "    return y[start:end]\n",
    "\n",
    "def compute_cochleagram(y, sr, n_ch=32, win_ms=25, hop_ms=10, fmin=80, fmax=None):\n",
    "    \"\"\"Cochleagram placeholder using Mel filterbank (stable & fast).\n",
    "       Drop-in replace with your gammatone if muốn.\n",
    "       Returns (n_ch, T) float32 in [0,1] after per-file minmax (mild) for visualization.\n",
    "    \"\"\"\n",
    "    win = int(sr*win_ms/1000)\n",
    "    hop = int(sr*hop_ms/1000)\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=2**int(np.ceil(np.log2(win))),\n",
    "        hop_length=hop, win_length=win, window=\"hann\",\n",
    "        n_mels=n_ch, fmin=fmin, fmax=fmax, power=1.0, center=True, htk=True\n",
    "    )  # shape (n_ch, T)\n",
    "    # amplitude compression (√) + small per-file minmax ONLY for display\n",
    "    S = np.sqrt(S + 1e-12)\n",
    "    return S.astype(np.float32)  # (n_ch, T)\n",
    "\n",
    "# --------------------------\n",
    "# 1) Dataset-wide normalisation (fit on TRAIN only)\n",
    "# --------------------------\n",
    "def fit_cochlea_norm(train_files, sr=16000, **coch_kwargs):\n",
    "    \"\"\"Compute per-channel mean/std across train set (after VAD).\"\"\"\n",
    "    ch = None\n",
    "    m_sum, v_sum, n_total = None, None, 0\n",
    "    for p in train_files:\n",
    "        y, _sr = librosa.load(p, sr=sr, mono=True)\n",
    "        y = vad_trim(y, sr)\n",
    "        C = compute_cochleagram(y, sr, **coch_kwargs)  # (n_ch, T)\n",
    "        if ch is None:\n",
    "            ch = C.shape[0]\n",
    "            m_sum = np.zeros(ch, dtype=np.float64)\n",
    "            v_sum = np.zeros(ch, dtype=np.float64)\n",
    "        m_sum += C.mean(axis=1)\n",
    "        v_sum += C.var(axis=1)\n",
    "        n_total += 1\n",
    "    mean = (m_sum / max(n_total,1)).astype(np.float32)\n",
    "    std  = np.sqrt(v_sum / max(n_total,1) + 1e-8).astype(np.float32)\n",
    "    return {\"mean\": mean, \"std\": std, \"sr\": sr, \"coch_kwargs\": coch_kwargs}\n",
    "\n",
    "def apply_norm(C, stats, per_channel=True):\n",
    "    \"\"\"z-score using dataset stats; keep nonnegative by linear scaling.\"\"\"\n",
    "    if per_channel:\n",
    "        Cn = (C - stats[\"mean\"][:, None]) / (stats[\"std\"][:, None] + 1e-8)\n",
    "    else:\n",
    "        mu, sd = C.mean(), C.std()\n",
    "        Cn = (C - mu) / (sd + 1e-8)\n",
    "    # squash to [0,1] with robust sigmoid-ish mapping\n",
    "    Cn = 1/(1+np.exp(-Cn))  # in (0,1)\n",
    "    return Cn.astype(np.float32)\n",
    "\n",
    "# --------------------------\n",
    "# 2) LIF with refractory + simple adaptation\n",
    "# --------------------------\n",
    "def lif_encode(C01, dt, tau_m=0.02, v0=0.15, gain=1.0,\n",
    "               refrac_s=0.003, a_jump=0.12, tau_a=0.08):\n",
    "    \"\"\"C01: (n_ch, T) in [0,1]. Returns spikes (n_ch, T) {0,1}.\"\"\"\n",
    "    n_ch, T = C01.shape\n",
    "    dt = float(dt)\n",
    "    v = np.zeros(n_ch, dtype=np.float32)\n",
    "    a = np.zeros(n_ch, dtype=np.float32)\n",
    "    refrac = np.zeros(n_ch, dtype=np.float32)\n",
    "    spikes = np.zeros((n_ch, T), dtype=np.uint8)\n",
    "\n",
    "    # precompute constants\n",
    "    decay_m = np.exp(-dt/tau_m)\n",
    "    decay_a = np.exp(-dt/tau_a)\n",
    "    refrac_steps = int(round(refrac_s/dt))\n",
    "\n",
    "    for t in range(T):\n",
    "        drive = gain * C01[:, t]  # [0, gain]\n",
    "        # integrate only if not refractory\n",
    "        active = (refrac <= 0.5)\n",
    "        v[active] = v[active]*decay_m + (1-decay_m)*drive[active]\n",
    "        a = a*decay_a\n",
    "        thr = v0 * (1.0 + a)  # adaptive threshold\n",
    "\n",
    "        # spike\n",
    "        s = (v > thr) & active\n",
    "        spikes[s, t] = 1\n",
    "        # reset + adaptation\n",
    "        v[s] = 0.0\n",
    "        a[s] += a_jump\n",
    "        refrac[s] = refrac_steps\n",
    "\n",
    "        # update refrac timers\n",
    "        refrac[refrac>0] -= 1.0\n",
    "    return spikes\n",
    "\n",
    "# --------------------------\n",
    "# 3) Target firing-rate tuning loop (per file) – keeps params within bounds\n",
    "# --------------------------\n",
    "def encode_with_rate_target(Cn, dt, target_hz=8.0, tol=1.0, max_iter=6,\n",
    "                            init_pct=0.80, init_gain=1.0,\n",
    "                            pct_bounds=(0.60,0.95), gain_bounds=(0.6, 3.5),\n",
    "                            **lif_kw):\n",
    "    \"\"\"Scale cochlea then LIF so that mean firing rate ≈ target_hz.\"\"\"\n",
    "    pct, gain = init_pct, init_gain\n",
    "    # scale by percentile per FILE to reduce outliers (mild)\n",
    "    flat = Cn.ravel()\n",
    "    for _ in range(max_iter):\n",
    "        scale = np.percentile(flat, pct*100)\n",
    "        C01 = np.clip(Cn/ (scale + 1e-8), 0, 1)\n",
    "        S = lif_encode(C01, dt, gain=gain, **lif_kw)\n",
    "        rate = S.sum() / (S.shape[0]*S.shape[1]*dt)  # Hz\n",
    "\n",
    "        if rate < target_hz - tol:\n",
    "            pct = max(pct_bounds[0], pct - 0.03)\n",
    "            gain = min(gain_bounds[1], gain * 1.15)\n",
    "        elif rate > target_hz + tol:\n",
    "            pct = min(pct_bounds[1], pct + 0.03)\n",
    "            gain = max(gain_bounds[0], gain * 0.85)\n",
    "        else:\n",
    "            return S, {\"pct\":pct, \"gain\":gain, \"rate\":rate}\n",
    "    # return last\n",
    "    return S, {\"pct\":pct, \"gain\":gain, \"rate\":rate}\n",
    "\n",
    "# --------------------------\n",
    "# 4) End-to-end: fit stats, then encode 1 file and plot\n",
    "# --------------------------\n",
    "def encode_file(path, stats,\n",
    "                target_hz=8.0, tol=1.0,\n",
    "                win_ms=25, hop_ms=10,\n",
    "                init_pct=0.95, init_gain=0.4,\n",
    "                v0=0.15, tau_m=0.02, refrac_s=0.003, a_jump=0.12, tau_a=0.08):\n",
    "    sr = stats[\"sr\"]\n",
    "    y, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    y = vad_trim(y, sr)\n",
    "    C = compute_cochleagram(y, sr, **stats[\"coch_kwargs\"])  # (n_ch, T)\n",
    "    Cn = apply_norm(C, stats, per_channel=True)\n",
    "    dt = hop_ms/1000.0\n",
    "    S, info = encode_with_rate_target(\n",
    "        Cn, dt, target_hz=target_hz, tol=tol,\n",
    "        init_pct=init_pct, init_gain=init_gain,\n",
    "        tau_m=tau_m, v0=v0, refrac_s=refrac_s, a_jump=a_jump, tau_a=tau_a\n",
    "    )\n",
    "    return C, Cn, S, info, dt\n",
    "\n",
    "def pad_or_crop_spike(S, T_target=100, align=\"left\"):\n",
    "    \"\"\"Pad or crop spike matrix S to T_target length.\"\"\"\n",
    "    n_ch, T = S.shape\n",
    "    if T == T_target:\n",
    "        return S\n",
    "    out = np.zeros((n_ch, T_target), dtype=S.dtype)\n",
    "    if T < T_target:\n",
    "        if align == \"left\":\n",
    "            out[:, :T] = S\n",
    "        elif align == \"right\":\n",
    "            out[:, -T:] = S\n",
    "        else:\n",
    "            start = (T_target - T) // 2\n",
    "            out[:, start:start+T] = S\n",
    "    else:\n",
    "        if align == \"left\":\n",
    "            out = S[:, :T_target]\n",
    "        elif align == \"right\":\n",
    "            out = S[:, -T_target:]\n",
    "        else:\n",
    "            start = (T - T_target) // 2\n",
    "            out = S[:, start:start+T_target]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c6d6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfiles = []\n",
    "for path in os.listdir(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/yes\"):\n",
    "    trainfiles.append(os.path.join(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/yes\", path))\n",
    "for path in os.listdir(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/no\"):\n",
    "    trainfiles.append(os.path.join(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/no\", path))\n",
    "\n",
    "stats = fit_cochlea_norm(trainfiles, sr=16000, n_ch=64, win_ms=25, hop_ms=10, fmin=80, fmax=7600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6da3b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in random.sample(os.listdir(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/yes\"), 200):\n",
    "    if filepath.endswith(\".wav\"):\n",
    "        file_path = os.path.join(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/yes\", filepath)\n",
    "        C, Cn, S, info, dt = encode_file(file_path, stats, target_hz=8.0, tol=1.0,\n",
    "                                 init_gain=0.6, init_pct=0.95,\n",
    "                                  v0=0.29, tau_m=0.015, refrac_s=0.003, a_jump=0.42, tau_a=0.07)\n",
    "        spike_matrix = pad_or_crop_spike(S, T_target=100, align=\"left\")\n",
    "        # print(f\"Processed {filepath} into spike matrix with shape {spike_matrix.shape}\")\n",
    "        \n",
    "        np.savez_compressed(f\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/spike_data/ch64/yes_{filepath[:-4]}.npz\", spike_matrix=spike_matrix, label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba0f1d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in random.sample(os.listdir(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/no\"), 200):\n",
    "    if filepath.endswith(\".wav\"):\n",
    "        file_path = os.path.join(\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/speech_command_dataset_v2/dataset/no\", filepath)\n",
    "        C, Cn, S, info, dt = encode_file(file_path, stats, target_hz=8.0, tol=1.0,\n",
    "                                 init_gain=0.6, init_pct=0.95,\n",
    "                                  v0=0.29, tau_m=0.015, refrac_s=0.003, a_jump=0.42, tau_a=0.07)\n",
    "        spike_matrix = pad_or_crop_spike(S, T_target=100, align=\"left\")\n",
    "        # print(f\"Processed {filepath} into spike matrix with shape {spike_matrix.shape}\")\n",
    "\n",
    "        np.savez_compressed(f\"/Users/minhhieunguyen/Documents/Projects/Dissertation/Code/spike_data/ch64/no_{filepath[:-4]}.npz\", spike_matrix=spike_matrix, label=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0e9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
